---
geometry:
- top=25mm
- left=20mm
- right=20mm
- bottom=30mm
documentclass: extarticle
fontsize: 12pt
numbersections: true
title: Lecture 19 (Instruction and Data Prefetching)
--- 

# Instruction Prefetching

## Next Line Prefetching
Spatial locality

## Markov Prefetching
1. High correlation between consecutive misses
1. Given that X incurs a miss, predict the line which will incur a next miss
1. Can have $n$ history as well

## Call Graph Prefetching
1. Function call is predictable
1. Predict and prefetch the function

### Hardware Approach Call Graph History Cache (CGHC)
1. Each entry contains a list of functions to be executed
1. Index is 1 initially
1. On returning from func1, prefetch func2

# Data Prefetching

## Stride Based Prefetching
1. Reference Prediction Table (RPT)
1. Each entry is made up of: instruction tag, previous address, stride, state

## Extension
1. Decide when to prefetch
1. Needs to be dynamic
1. Depends on code in the loop

## Pointer Chasing
1. No visible hardware pattern
1. Can insert code to actually prefetch node->next
1. `gcc_intrinsics.h` exists for this

*exists a term called black belt programmer*

## Runahead Mode
1. Misses in L1 (especially L2) lead to stalls since IW and ROB fill up
1. Idea is to do some work during stall period

### Implementation
1. Return a a junk value for the miss
1. Restart execution with junk value - add INV (invalid) bit
1. This is useful since we will prefetch data and train predictors
1. Once miss returns, flush instructions and re-execute instructions
1. For data requests during this time, maintain a runahead L1 cache

#### Runahead L1
1. If store is INV because of data (not because of address), prefetch this address
1. Can maintain additional state of INV and INV store

#### Loading Value
1. Try forwarding in LSQ
1. Else, access runahead cache
1. If miss, try accessing from L1
1. Else, load from L2 (prefetching)

## Helper Threads
1. Spawn threads to execute backward slice of load
1. Backward slice determines the address of load
1. If resources available, saves time
